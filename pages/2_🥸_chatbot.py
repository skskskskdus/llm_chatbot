import streamlit as st
import zipfile
import json
import os
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.prompts import ChatPromptTemplate
from langchain.chains import ConversationChain
from langchain.llms import OpenAI
from langchain.docstore.document import Document
from streamlit_extras.let_it_rain import rain
from langchain.output_parsers import PydanticOutputParser
from dotenv import load_dotenv
from glob import glob

import time

# OpenAI API í‚¤ ì„¤ì •
# API í‚¤ ì •ë³´ ë¡œë“œ
load_dotenv()

# OpenAI API í‚¤ ì„¤ì •
OPENAI_API_KEY =   "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"
 # ì‹¤ì œ API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”
os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="chatbot", page_icon="ğŸ¥¸")
st.title('ğŸˆâ€â¬›ë‚˜ë§Œì˜ ì§‘ì‚¬ë‹˜ğŸˆâ€â¬›')

# ì¸¡ë©´ ë°”ì— ë¹„ë””ì˜¤ ì¶”ê°€
st.sidebar.video("https://youtu.be/FoO7Pmx0bE4")

# ê¸°ë³¸ ëª¨ë¸ ì„¤ì •
if "model" not in st.session_state:
    st.session_state["model"] = "gpt-4o"

# ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# ZIP íŒŒì¼ í•´ì œ ë° JSON ë°ì´í„° ì½ê¸°
zip_file_path = os.path.join("ai_data", "TL_02. ì¶”ì²œì§ì—… ì¹´í…Œê³ ë¦¬_01. ê¸°ìˆ ê³„ì—´.zip")
extract_dir = os.path.join("data", "data")
json_file_path = os.path.join(extract_dir, "ì „ë¬¸ê°€_ë¼ë²¨ë§_ë°ì´í„°_ê¸°ìˆ ê³„ì—´.json")

if "retriever" not in st.session_state:

    # ë””ë ‰í† ë¦¬ ë‚´ì˜ ëª¨ë“  JSON íŒŒì¼ ê²½ë¡œë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ê°€ì ¸ì˜¤ê¸°
    json_files = glob(os.path.join('data', '*.json'))

    # ëª¨ë“  JSON ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    career_data = []

    # ê° JSON íŒŒì¼ ë¡œë“œ ë° ë°ì´í„° ì¶”ê°€
    for json_file in json_files:
        try:
            with open(json_file, 'r', encoding='utf-8') as file:
                data = json.load(file)
                career_data.extend(data)  # ë°ì´í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
        except FileNotFoundError:
            st.error(f"{json_file}ì— JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except json.JSONDecodeError:
            st.error(f"{json_file}ì˜ JSON íŒŒì¼ì„ ë””ì½”ë”©í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

    # JSON ë°ì´í„°ë¥¼ Document ê°ì²´ë¡œ ë³€í™˜
    documents = [Document(page_content=json.dumps(item, ensure_ascii=False)) for item in career_data]
    
    # í…ìŠ¤íŠ¸ ë¶„í• :RecursiveCharacterTextSplitterì„ ì´ìš©í•´ì„œ  chunkì˜ í¬ê¸°ë¥¼ 500ìœ¼ë¡œ ì§€ì •,ì¸ì ‘í•œ ì¤‘ë³µ ë¬¸ì ìˆ˜ 20ìœ¼ë¡œ ì„¤ì •
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)
    splits = text_splitter.split_documents(documents) #documentsì˜ ë¶„í• ëœ ë°ì´í„°ê°€ splitsì— ì €ì¥ë¨
    print("Chunks split Done.")
    
    # ì„ë² ë”© ë° ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±, ê²€ìƒ‰
    embedding = OpenAIEmbeddings(api_key=OPENAI_API_KEY)
    #ë²¡í„° ë² ì´ìŠ¤ FAISS ì‚¬ìš©:ëŒ€ë‘ì˜ ë°ì´í„°ì¼ ê²½ìš° ì„±ëŠ¥ì´ ì¢‹ìŒ
    vectordb = FAISS.from_documents(documents, embedding)
    print("Retriever Done.")
   #ë°ì´í„° ë² ì´ìŠ¤ë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆëŠ” ê°ì²´ ìƒì„±
    st.session_state.retriever = vectordb.as_retriever()

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
prompt = ChatPromptTemplate.from_template(
    """
    ë„ˆëŠ” ì§„ë¡œ ìƒë‹´ì„ ìœ„í•œ ì±—ë´‡ì´ì•¼. 
    ê¸°ìˆ  ê³„ì—´ ìƒë‹´ ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•  ìˆ˜ ìˆë„ë¡ í•™ìŠµë˜ì—ˆì–´. 
    ìƒë‹´ ë°ì´í„° ì™¸ì˜ ì§ˆë¬¸ì€ OpenAIì˜ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•  ìˆ˜ ìˆë„ë¡ ë˜ì–´ ìˆì–´.

    Answer the question based only on the following context:
    {context}

    Question: {question}
    """
)
# ê²€ìƒ‰í•œ ë¬¸ì„œ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë¬¸ë‹¨ìœ¼ë¡œ í•©ì³ì¤ë‹ˆë‹¤.
def format_docs(docs):
    return '\n\n'.join(doc.page_content for doc in docs)
#llm ëª¨ë¸ ìƒì„±
llm = OpenAI(api_key=OPENAI_API_KEY, model="gpt-4o", temperature=0)

# RAG Chain ì—°ê²°
rag_chain = (
    {'context': st.session_state.retriever | format_docs, 'question': RunnablePassthrough()}
    | prompt
    | llm
    | PydanticOutputParser()
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'conversation' not in st.session_state:
    st.session_state.conversation = []

# ì‘ë‹µ ìƒì„± í•¨ìˆ˜ ìˆ˜ì •
def generate_response(input_text):
    input_string = str(input_text)
    response = rag_chain.invoke(input_string)
    return response

# ì§ˆë¬¸ ì–‘ì‹
with st.form('Question'):
    text = st.text_area('ì˜¤ì¡°ì‚¬ë§ˆ ì…ë ¥:', placeholder='ì•¼ë ˆ ì•¼ë ˆ ë˜ ì§ˆë¬¸í•˜ëŠ” ê±°ì˜ˆìš”?')
    submitted = st.form_submit_button("ì§ˆë¬¸í•´ë³¼ê¹Œìš”?")
    if submitted:
        response = generate_response(text)
        st.session_state.conversation.insert(0, {'question': text, 'response': response})

# ëŒ€í™” ê¸°ë¡ í‘œì‹œ
for chat in st.session_state.conversation:
    st.write(f"**ì˜¤ì¡°ì‚¬ë§ˆ:** {chat['question']}")
    st.info(f"**ì§‘ì‚¬:** {chat['response']}")

# ëŒ€í™” ì €ì¥ ë²„íŠ¼
if st.button("ëŒ€í™” ì €ì¥"):
    if not os.path.exists('conversations'):
        os.makedirs('conversations')
    
    file_path = os.path.join('conversations', 'conversation.py')
    
    # íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ” ê²½ìš° ì´ì „ ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸°
    if os.path.exists(file_path):
        with open(file_path, "r", encoding='utf-8') as file:
            exec(file.read(), globals(), locals())
    
    with open(file_path, "w", encoding='utf-8') as file:
        file.write("# ëŒ€í™” ê¸°ë¡\n")
        file.write("conversation = [\n")
        for chat in st.session_state.conversation:
            file.write(f"    {{'question': '''{chat['question']}''', 'response': '''{chat['response']}'''}},\n")
        if 'conversation' in locals():
            for chat in conversation:
                file.write(f"    {{'question': '''{chat['question']}''', 'response': '''{chat['response']}'''}},\n")
        file.write("]\n")
    st.success(f"ëŒ€í™”ê°€ 'conversations/conversation.py' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

# ì €ì¥ëœ ëŒ€í™” í‘œì‹œ ë²„íŠ¼
if st.button("ì €ì¥ëœ ëŒ€í™” í‘œì‹œ"):
    try:
        with open(os.path.join('conversations', 'conversation.py'), "r", encoding='utf-8') as file:
            exec(file.read(), globals(), locals())
            if 'conversation' in locals():
                for chat in conversation:
                    st.write(f"**ì˜¤ì¡°ì‚¬ë§ˆ:** {chat['question']}")
                    st.info(f"**ì§‘ì‚¬:** {chat['response']}")
            else:
                st.error("íŒŒì¼ì—ì„œ ì €ì¥ëœ ëŒ€í™”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except FileNotFoundError:
        st.error("ì €ì¥ëœ ëŒ€í™” íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        st.error(f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# ì‹œê°ì  íš¨ê³¼ í•¨ìˆ˜
def rose():
    rain(
        emoji="ğŸŒ¹",
        font_size=54,
        falling_speed=5,
        animation_length="infinite",
    )

rose()
